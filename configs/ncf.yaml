batch_size: 1024
learning_rate: 0.001
epochs: 10
mlp_emb_size: 8
num_negatives: 4
layers: [16,64,32,16,8]
l2_reg: 0.0000001

save_best: True