batch_size: 256
learning_rate: 0.001
epochs: 50
mlp_emb_size: 64
num_negatives: 4
layers: [64,32,16,8]
l2_reg: 0.000001

save_best: True